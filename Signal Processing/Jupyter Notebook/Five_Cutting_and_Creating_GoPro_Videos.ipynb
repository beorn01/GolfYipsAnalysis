{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#33335 Cutting_and_Creating_Putting_Videos\n",
    "# Jupyter Notebook Setup\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of participant numbers\n",
    "participant_numbers = [\"059\"]\n",
    "\n",
    "# participant_numbers = [ \"046\", \"062\", \"063\", \"064\" , \"065\" ,\"066\" ,\"067\"]\n",
    "\n",
    "\n",
    "\n",
    "# List of configurations for various conditions and hand types\n",
    "configurations = [\n",
    "    # {'condition': 'Ball', 'hand_type': 'BH'},\n",
    "    {'condition': 'Ball', 'hand_type': 'RH'},\n",
    "    # {'condition': 'Ball', 'hand_type': 'LH'}\n",
    "    # {'condition': 'NB', 'hand_type': 'BH'},\n",
    "    # {'condition': 'NB', 'hand_type': 'RH'},\n",
    "    # {'condition': 'NB', 'hand_type': 'LH'}\n",
    "    # Add more configurations as needed\n",
    "]\n",
    "\n",
    "# Function to extract video metadata\n",
    "def extract_metadata(video_path):\n",
    "    data = {'Total Frames': None, 'Timecode': None, 'Creation Time': None, 'Frame Rate': None, 'Audio Sample Rate': None, 'Fused Timecode': None, 'File Path': video_path}\n",
    "    video_metadata_command = (f'ffprobe -v error -select_streams v:0 -show_entries stream=nb_frames,r_frame_rate,duration -show_entries stream_tags=timecode -show_entries format_tags=creation_time -of default=noprint_wrappers=1 \"{video_path}\"')\n",
    "    audio_metadata_command = (f'ffprobe -v error -select_streams a:0 -show_entries stream=sample_rate -of default=noprint_wrappers=1 \"{video_path}\"')\n",
    "    video_metadata_process = subprocess.run(video_metadata_command, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    audio_metadata_process = subprocess.run(audio_metadata_command, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    if video_metadata_process.returncode == 0:\n",
    "        for line in video_metadata_process.stdout.split('\\n'):\n",
    "            if 'nb_frames' in line:\n",
    "                _, value = line.split('=')\n",
    "                data['Total Frames'] = value.strip()\n",
    "            elif 'TAG:timecode' in line:\n",
    "                _, value = line.split('=')\n",
    "                data['Timecode'] = value.strip()\n",
    "            elif 'TAG:creation_time' in line:\n",
    "                _, value = line.split('=')\n",
    "                data['Creation Time'] = value.strip()\n",
    "            elif 'r_frame_rate' in line:\n",
    "                _, value = line.split('=')\n",
    "                numerator, denominator = map(int, value.strip().split('/'))\n",
    "                data['Frame Rate'] = str(numerator / denominator if denominator != 0 else numerator)\n",
    "        if data['Creation Time'] and data['Timecode']:\n",
    "            creation_datetime = datetime.strptime(data['Creation Time'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            time_parts = data['Timecode'].split(':')\n",
    "            if len(time_parts) == 4:\n",
    "                fused_timecode = f\"{creation_datetime.strftime('%Y-%m-%d')}T{time_parts[0]}:{time_parts[1]}:{time_parts[2]}.{int(time_parts[3]):02d}Z\"\n",
    "                data['Fused Timecode'] = fused_timecode\n",
    "    else:\n",
    "        print(\"Error extracting video metadata:\", video_metadata_process.stderr)\n",
    "    if audio_metadata_process.returncode == 0:\n",
    "        for line in audio_metadata_process.stdout.split('\\n'):\n",
    "            if 'sample_rate' in line:\n",
    "                _, value = line.split('=')\n",
    "                data['Audio Sample Rate'] = value.strip()\n",
    "    else:\n",
    "        print(\"Error extracting audio metadata:\", audio_metadata_process.stderr)\n",
    "    return data\n",
    "\n",
    "# Function to find the closest frame\n",
    "def find_closest_frame(target_index, frame_values):\n",
    "    closest_frame_idx = None\n",
    "    min_difference = float('inf')\n",
    "    for idx, value in enumerate(frame_values):\n",
    "        difference = abs(value - target_index)\n",
    "        if difference < min_difference:\n",
    "            min_difference = difference\n",
    "            closest_frame_idx = idx\n",
    "    print(f\"Minimum difference for target index {target_index} is {min_difference}.\")\n",
    "    return closest_frame_idx, min_difference\n",
    "\n",
    "# Iterate through each participant and configuration\n",
    "for participant in participant_numbers:\n",
    "    for config in configurations:\n",
    "        condition = config['condition']\n",
    "        hand_type = config['hand_type']\n",
    "\n",
    "        # Paths for alignment and index data\n",
    "        aligned_data_path = f\"/Volumes/Beorn_4T/Experiment Data/SDC_{participant}/Time_Axis_Alignmen_Python.json\"\n",
    "        peak_indexes_path = f\"/Volumes/Beorn_4T/Experiment Data/SDC_{participant}/Putt_Index_Locations.json\"\n",
    "        video_read_path = f\"/Volumes/Beorn_4T/Experiment Data/SDC_{participant}/Videos/Videopanel/SDC_{participant}_{condition}_{hand_type}_VP.MP4\"\n",
    "\n",
    "        # Load aligned data\n",
    "        with open(aligned_data_path, 'r') as json_file:\n",
    "            Time_Axis_Alignment = json.load(json_file)\n",
    "\n",
    "        # Load peak indexes\n",
    "        with open(peak_indexes_path, 'r') as file:\n",
    "            Index_Locations = json.load(file)\n",
    "\n",
    "        # Extract index locations and time alignment data for the current condition and hand type\n",
    "        ball_BH_indexes = Index_Locations[condition][hand_type]\n",
    "        condition_data = Time_Axis_Alignment[condition]  # Access data for the specified condition\n",
    "        hand_type_data = condition_data[hand_type]       # Access data for the specified hand type\n",
    "\n",
    "        BH_time_block = hand_type_data['data']\n",
    "        BH_time_block = [row[0] for row in BH_time_block if len(row) > 0]\n",
    "        offset = hand_type_data['offset']\n",
    "\n",
    "        # Open video and ensure it's accessible\n",
    "        cap = cv2.VideoCapture(video_read_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(f\"Error opening video file {video_read_path}.\")\n",
    "\n",
    "        # Define the output directory\n",
    "        output_dir = f\"/Volumes/Beorn_4T/Experiment Data/SDC_{participant}/Videos/Videopanel/cut_segments{condition}_{hand_type}/\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Amount to crop from the bottom\n",
    "        crop_from_bottom = 600\n",
    "\n",
    "        # Process each index\n",
    "        for index in ball_BH_indexes:\n",
    "            frame_number, min_difference = find_closest_frame(index, BH_time_block)\n",
    "            if frame_number is not None and min_difference < 20:\n",
    "                start_frame = max((frame_number) - 150, 0) - offset\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "                ret, first_frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Failed to read the frame at {start_frame}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Crop the first frame from the bottom\n",
    "                height, width = first_frame.shape[:2]\n",
    "                cropped_height = max(height - crop_from_bottom, 0)\n",
    "                cropped_first_frame = first_frame[:cropped_height, :]\n",
    "\n",
    "                # Set up video writer\n",
    "                output_filename = f\"{output_dir}segment_{index}.mp4\"\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "                out = cv2.VideoWriter(output_filename, fourcc, 100, (int(cropped_first_frame.shape[1]), int(cropped_first_frame.shape[0])))\n",
    "\n",
    "                out.write(cropped_first_frame)\n",
    "                count = 1\n",
    "                while count < 401:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(f\"Failed to read frame at count {count}.\")\n",
    "                        break\n",
    "                    cropped_frame = frame[:cropped_height, :]\n",
    "                    out.write(cropped_frame)\n",
    "                    count += 1\n",
    "                out.release()\n",
    "            else:\n",
    "                print(f\"Skipping index {index}: No close frame found within tolerance or minimum difference too high.\")\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Video segments have been successfully extracted, cropped, and saved for participant {participant}, condition {condition}, and hand type {hand_type}.\")\n",
    "\n",
    "print(\"All configurations have been processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabWork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
